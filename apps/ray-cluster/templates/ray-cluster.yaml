apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: raycluster-autoscaler
spec:
  rayVersion: '2.9.3'
  enableInTreeAutoscaling: true
  autoscalerOptions:
    upscalingMode: Default
    idleTimeoutSeconds: 60
    imagePullPolicy: IfNotPresent
    securityContext: {}
    env: []
    envFrom: []
    resources:
      limits:
        cpu: "500m"
        memory: "512Mi"
      requests:
        cpu: "500m"
        memory: "512Mi"
  headGroupSpec:
    rayStartParams:
      num-cpus: "0"
    template:
      spec:
        containers:
        - name: ray-head
          image: rayproject/ray:2.9.3.b8d0cb-py311
          ports:
          - containerPort: 6379
            name: gcs
          - containerPort: 8265
            name: dashboard
          - containerPort: 10001
            name: client
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","ray stop"]
          resources:
            limits:
              cpu: "1"
              memory: "2G"
            requests:
              cpu: "1"
              memory: "2G"
          volumeMounts:
            - name: persistent-storage
              mountPath: /data
        tolerations:
        - key: "experiment-name"
          operator: "Equal"
          value: {{ .Values.namespace }}
          effect: "NoSchedule"
        volumes:
          - name: persistent-storage
            persistentVolumeClaim:
              claimName: {{ .Values.namespace }}
  workerGroupSpecs:
  - replicas: 0
    minReplicas: 0
    maxReplicas: 10
    groupName: worker-group
    rayStartParams: {}
    template:
      spec:
        containers:
        - name: ray-worker
          {{- if eq .Values.experimentSize "gpu-large" }}
          image: rayproject/ray:2.9.3.b8d0cb-py311-gpu
          {{- else }}
          image: rayproject/ray:2.9.3.b8d0cb-py311
          {{- end }}
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","ray stop"]
          resources:
          {{- if eq .Values.experimentSize "gpu-large" }}
            limits:
              cpu: "7"
              memory: "30G"
              nvidia.com/gpu: 1
          {{- else }}
            limits:
              cpu: "2"
              memory: "4G"
          {{- end }}
          volumeMounts:
            - name: persistent-storage
              mountPath: /data
        tolerations:
        - key: "experiment-name"
          operator: "Equal"
          value: {{ .Values.namespace }}
          effect: "NoSchedule"
        {{- if eq .Values.experimentSize "gpu-large" }}
        - key: nvidia.com/gpu
          operator: "Exists"
          effect: NoSchedule
        {{- end }}
        volumes:
          - name: persistent-storage
            persistentVolumeClaim:
              claimName: {{ .Values.namespace }}
